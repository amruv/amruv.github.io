"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[930],{9930:function(e,t,n){n.r(t),n.d(t,{frontmatter:function(){return a}});var r=n(7437),s=n(5595);let a={title:"How tf do LLMs work? - Part 2",description:"It all starts with a bit of attention-seeking, I suppose.",date:"2025-09-07",readTime:"12 min read",tags:["transformers","llm","attention","machine-learning"],category:"TUTORIAL",gradient:"from-blue-500/20 to-purple-500/20"};function i(e){let t=Object.assign({h1:"h1",p:"p"},(0,s.ah)(),e.components);return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(t.h1,{children:"[Part 2] How tf do LLMs work?"}),"\n",(0,r.jsx)(t.p,{children:"This is a placeholder while we wire up MDX correctly."})]})}t.default=function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:t}=Object.assign({},(0,s.ah)(),e.components);return t?(0,r.jsx)(t,Object.assign({},e,{children:(0,r.jsx)(i,e)})):i(e)}}}]);