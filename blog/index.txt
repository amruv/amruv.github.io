2:I[1211,["972","static/chunks/972-fa1913aa38d3d642.js","917","static/chunks/917-10a9c1de1815245a.js","404","static/chunks/app/blog/page-46d5a77276700a5c.js"],"default"]
3:I[5932,["972","static/chunks/972-fa1913aa38d3d642.js","917","static/chunks/917-10a9c1de1815245a.js","404","static/chunks/app/blog/page-46d5a77276700a5c.js"],"default"]
4:I[4707,[],""]
5:I[6423,[],""]
0:["6wdKysRoAQkj6Y7Bp1o90",[[["",{"children":["blog",{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],["",{"children":["blog",{"children":["__PAGE__",{},[["$L1",["$","main",null,{"className":"min-h-screen bg-background text-foreground","children":[["$","$L2",null,{}],["$","div",null,{"className":"bg-background border-b border-border pt-20","children":["$","div",null,{"className":"max-w-7xl mx-auto px-6 py-8","children":["$","div",null,{"className":"text-center","children":[["$","h1",null,{"className":"text-5xl font-bold mb-4 test-font-courier text-primary","children":"Blog"}],["$","p",null,{"className":"text-xl text-muted-foreground max-w-2xl mx-auto test-font-mono","children":"Sharing insights, tutorials, and thoughts on machine learning research and development"}]]}]}]}],["$","div",null,{"className":"max-w-7xl mx-auto px-6 py-20","children":["$","$L3",null,{"posts":[{"slug":"s1e1","title":"How tf do LLMs work? - Part 1: Intro to Transformers","description":"It all starts with a bit of attention-seeking, I suppose.","date":"2025-09-07","readTime":"10 min read","tags":["transformers","llm","attention","machine learning"],"category":"EXPLAINER","gradient":"from-blue-500/20 to-purple-500/20"},{"slug":"s1e2","title":"How tf do LLMs work? - Part 2: Input Processing","description":"From words to tokens to ordered vectors - the crucial preprocessing pipeline","date":"2025-09-14","readTime":"8 min read","tags":["transformers","llm","tokenization","embeddings","positional-encoding"],"series":"How tf do LLMs work?","category":"EXPLAINER","part":2,"gradient":"from-purple-500/20 to-pink-500/20"},{"slug":"s1e3","title":"How tf do LLMs work? - Part 3: Multi-Head Attention","description":"Understanding the attention mechanism - the engine that powers transformers","date":"2025-09-28","readTime":"8 min read","tags":["transformers","llm","attention","multi-head-attention","self-attention"],"series":"How tf do LLMs work?","category":"EXPLAINER","part":3,"gradient":"from-pink-500/20 to-orange-500/20"}]}]}]]}],null],null],null]},[null,["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined"}]],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/7f3985922bdd9a6d.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"en","className":"dark","children":[["$","head",null,{"children":["$","meta",null,{"name":"viewport","content":"width=device-width, initial-scale=1"}]}],["$","body",null,{"className":"__className_f367f3","children":["$","div",null,{"className":"min-h-screen bg-background text-foreground","children":["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]}]}]]}]],null],null],["$L6",null]]]]
6:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Sai Amruth Balusu"}],["$","meta","3",{"name":"description","content":"Personal website of Sai Amruth Balusu, Machine Learning Researcher specializing in transformers, computer vision, and distributed systems."}],["$","meta","4",{"name":"author","content":"Sai Amruth Balusu"}],["$","meta","5",{"name":"keywords","content":"machine learning,AI research,deep learning,transformers,computer vision"}],["$","meta","6",{"property":"og:title","content":"Sai Amruth Balusu - ML Researcher"}],["$","meta","7",{"property":"og:description","content":"Personal website showcasing research, publications, and projects in machine learning."}],["$","meta","8",{"property":"og:url","content":"https://amruv.github.io/"}],["$","meta","9",{"property":"og:site_name","content":"Sai Amruth Balusu"}],["$","meta","10",{"property":"og:image","content":"https://amruv.github.io/og-image.png"}],["$","meta","11",{"property":"og:image:width","content":"1200"}],["$","meta","12",{"property":"og:image:height","content":"630"}],["$","meta","13",{"property":"og:image:alt","content":"Sai Amruth Balusu - ML Researcher"}],["$","meta","14",{"property":"og:type","content":"website"}],["$","meta","15",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","16",{"name":"twitter:title","content":"Sai Amruth Balusu - ML Researcher"}],["$","meta","17",{"name":"twitter:description","content":"Personal website showcasing research, publications, and projects in machine learning."}],["$","meta","18",{"name":"twitter:image","content":"https://amruv.github.io/og-image.png"}],["$","meta","19",{"name":"next-size-adjust"}]]
1:null
